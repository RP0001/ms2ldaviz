{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts from the old LDA project into the new dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import cPickle\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/joewandy/git/MS2LDA/')\n",
    "sys.path.append('/Users/joewandy/git/lda/code')\n",
    "\n",
    "from lda import VariationalLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_proj(project_in):\n",
    "    with gzip.GzipFile(project_in, 'rb') as f:\n",
    "        obj = cPickle.load(f)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def copy_mat_to_dict(mat, row_labels, col_labels):\n",
    "\n",
    "    n_row, n_col = mat.shape\n",
    "    assert n_row == len(row_labels)\n",
    "    assert n_col == len(col_labels)\n",
    "    \n",
    "    result = {}\n",
    "    nnz = 0\n",
    "    for i in range(n_row):\n",
    "        dist = {}\n",
    "        row_label = row_labels[i]\n",
    "        for j in range(n_col):\n",
    "            col_label = col_labels[j]\n",
    "            val = mat[i, j]\n",
    "            if val > 0:\n",
    "                dist[col_label] = val\n",
    "                nnz += 1\n",
    "        result[row_label] = dist\n",
    "\n",
    "    print nnz, '/', (mat.shape[0]*mat.shape[1]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_indices(document, sparse=False):\n",
    "    \"\"\"\n",
    "    Turns a document vector of word counts into a vector of the indices\n",
    "     words that have non-zero counts, repeated for each count\n",
    "    e.g.\n",
    "    >>> word_indices(np.array([3, 0, 1, 2, 0, 5]))\n",
    "    [0, 0, 0, 2, 3, 3, 5, 5, 5, 5, 5]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for nnz in document.values.nonzero()[1]:\n",
    "        count = document.values[0].flatten()\n",
    "        for n in range(int(count[nnz])):\n",
    "            results.append(nnz)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_contributions(proj, parent_peak_id, min_prob_to_keep_phi):\n",
    "\n",
    "    # work out the contributions of different M2Ms\n",
    "    row_idx = proj.ms1['peakID'] == parent_peak_id\n",
    "    pos = np.nonzero(row_idx.values)[0]\n",
    "    d = np.asscalar(pos)\n",
    "    motifs_of_interest = np.nonzero(proj.doc_topic[d])[0].tolist()\n",
    "\n",
    "    document = proj.df.iloc[[d]]\n",
    "    word_idx = word_indices(document)\n",
    "    results = {}\n",
    "    for pos in range(len(word_idx)):\n",
    "        n = word_idx[pos]\n",
    "        k = proj.model.Z[(d, pos)]\n",
    "        word = proj.vocab[n]\n",
    "        if word in results:\n",
    "            results[word].append(k)\n",
    "        else:\n",
    "            results[word] = [k]\n",
    "\n",
    "    contributions = {}\n",
    "    for word in results:\n",
    "        topics = Counter(results[word])\n",
    "        total = float(np.sum(topics.values()))\n",
    "        ratio = { key : (topics[key]/total) for key in topics}\n",
    "        contributions[word] = ratio\n",
    "        \n",
    "    new_contrib = {}\n",
    "    for word in contributions:\n",
    "        word_contrib = contributions[word]\n",
    "        new_word_contrib = {}\n",
    "        for topic in word_contrib:\n",
    "            topic_name = 'motif_%d' % topic\n",
    "            val = word_contrib[topic]\n",
    "            if val > min_prob_to_keep_phi:\n",
    "                new_word_contrib[topic_name] = val\n",
    "        new_contrib[word] = new_word_contrib\n",
    "\n",
    "    return new_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_proj_to_dict(proj, min_prob_to_keep_beta, min_prob_to_keep_theta, min_prob_to_keep_phi):\n",
    "    \n",
    "    # build metadata\n",
    "    ms1 = proj.ms1\n",
    "    metadata = {}\n",
    "    docs = []\n",
    "    parent_peak_ids = []\n",
    "    for index, row in ms1.iterrows():\n",
    "\n",
    "        mz = row['mz']\n",
    "        rt = row['rt']\n",
    "        intensity = row['intensity']\n",
    "        pid = row['peakID']\n",
    "        \n",
    "        key = '%s_%s' % (row['mz'], row['rt'])\n",
    "        docs.append(key)\n",
    "        parent_peak_ids.append(row['peakID'])\n",
    "        \n",
    "        metadata[key] = {}\n",
    "        metadata[key]['parentmass'] = mz\n",
    "        metadata[key]['rt'] = rt\n",
    "        metadata[key]['intensity'] = intensity\n",
    "        metadata[key]['id'] = pid \n",
    "\n",
    "    # build corpus\n",
    "    vocab = proj.vocab\n",
    "    mat = proj.df.values\n",
    "    n_docs, n_words = mat.shape\n",
    "    assert n_docs == len(docs)\n",
    "    assert n_words == len(vocab)\n",
    "\n",
    "    corpus = {}\n",
    "    for d in range(n_docs):\n",
    "        doc = {}\n",
    "        for n in range(n_words):\n",
    "            val = mat[d, n]\n",
    "            if val > 0:\n",
    "                word = vocab[n]\n",
    "                doc[word] = val\n",
    "\n",
    "        doc_id = docs[d]\n",
    "        corpus[doc_id] = doc\n",
    "\n",
    "    K = proj.model.K\n",
    "    alpha = proj.model.posterior_alpha.tolist()\n",
    "\n",
    "    # build the doc index\n",
    "    doc_index = {}\n",
    "    for d in range(len(docs)):\n",
    "        doc_id = docs[d]\n",
    "        doc_index[doc_id] = d\n",
    "\n",
    "    # build the word index\n",
    "    word_index = {}\n",
    "    for n in range(len(vocab)):\n",
    "        word = vocab[n]\n",
    "        word_index[word] = n\n",
    "        \n",
    "    proj.do_thresholding(th_topic_word=min_prob_to_keep_beta, th_doc_topic=min_prob_to_keep_theta)\n",
    "    \n",
    "    # create beta\n",
    "    print 'Beta'\n",
    "    row_labels = ['motif_%d' % k for k in range(K)]\n",
    "    col_labels = vocab\n",
    "    beta = copy_mat_to_dict(proj.topic_word, row_labels, col_labels)\n",
    "\n",
    "    # create theta\n",
    "    print 'Theta'\n",
    "    row_labels = docs\n",
    "    col_labels = ['motif_%d' for k in range(K)]\n",
    "    theta = copy_mat_to_dict(proj.doc_topic, row_labels, col_labels)\n",
    "    \n",
    "    # create phi\n",
    "    print 'Phi'\n",
    "    phi = {}\n",
    "    for d in range(n_docs):\n",
    "        doc_id = docs[d]\n",
    "        pid = parent_peak_ids[d]\n",
    "        contrib = get_contributions(proj, pid, min_prob_to_keep_phi)        \n",
    "        phi[doc_id] = contrib\n",
    "\n",
    "    # create the final dict\n",
    "    lda_dict = {}\n",
    "    lda_dict['corpus'] = corpus\n",
    "    lda_dict['word_index'] = word_index\n",
    "    lda_dict['doc_index'] = doc_index\n",
    "    lda_dict['K'] = K\n",
    "    lda_dict['alpha'] = alpha\n",
    "    lda_dict['beta'] = beta\n",
    "    lda_dict['theta'] = theta\n",
    "    lda_dict['phi'] = phi\n",
    "    lda_dict['doc_metadata'] = metadata\n",
    "    \n",
    "    return lda_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_topic_metadata(filename):\n",
    "    topic_metadata = {}\n",
    "    for item in csv.reader(open(filename), skipinitialspace=True):\n",
    "        key = int(item[0])\n",
    "        topic_name = 'motif_%d' % key\n",
    "        val = item[1]\n",
    "        topic_metadata[topic_name] = val\n",
    "    return topic_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_dict(lda_dict, filename):\n",
    "    with open(filename,'w') as f:\n",
    "        pickle.dump(lda_dict, f, -1)\n",
    "    print 'Saved to %s' % filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_dir = '/Users/joewandy/Dropbox/MS2LDA Manuscript Sections/Supporting Information/'\n",
    "proj_file = 'Manuscript_Beer1POSmode_EFassigner_ALLextended.project'\n",
    "annot_file = 'beer1pos_annotation_Nov2015.csv'\n",
    "out_file = 'beer1pos.dict'\n",
    "proj = load_proj(os.path.join(proj_dir, proj_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(proj_dir, proj_file, annot_file, out_file):\n",
    "\n",
    "    min_prob_to_keep_beta = 1e-3\n",
    "    min_prob_to_keep_theta = 1e-2\n",
    "    min_prob_to_keep_phi = 1e-2\n",
    "    \n",
    "    proj = load_proj(os.path.join(proj_dir, proj_file))\n",
    "    topic_metadata = load_topic_metadata(os.path.join(proj_dir, annot_file))\n",
    "\n",
    "    lda_dict = convert_proj_to_dict(proj, min_prob_to_keep_beta, min_prob_to_keep_theta, min_prob_to_keep_phi)\n",
    "    lda_dict['topic_metadata'] = topic_metadata\n",
    "    \n",
    "    save_dict(lda_dict, os.path.join(proj_dir, out_file))\n",
    "    \n",
    "    return lda_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_dir = '/Users/joewandy/Dropbox/MS2LDA Manuscript Sections/Supporting Information/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_file = 'Manuscript_Beer1POSmode_EFassigner_ALLextended.project'\n",
    "annot_file = 'beer1pos_annotation_Nov2015.csv'\n",
    "out_file = 'beer1pos.dict'\n",
    "lda_dict = convert(proj_dir, proj_file, annot_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_file = 'Manuscript_Beer2POSmode_EFassigner_ALLextended.project'\n",
    "annot_file = 'beer2pos_annotation_Nov2015.csv'\n",
    "out_file = 'beer2pos.dict'\n",
    "lda_dict = convert(proj_dir, proj_file, annot_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_file = 'Manuscript_Beer3POSmode_EFassigner_ALLextended.project'\n",
    "annot_file = 'beer3pos_annotation_Nov2015.csv'\n",
    "out_file = 'beer3pos.dict'\n",
    "lda_dict = convert(proj_dir, proj_file, annot_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_file = 'Manuscript_BeerQCPOSmode_EFassigner_ALLextended.project'\n",
    "annot_file = 'beer4pos_annotation_Nov2015.csv'\n",
    "out_file = 'beer4pos.dict'\n",
    "lda_dict = convert(proj_dir, proj_file, annot_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
